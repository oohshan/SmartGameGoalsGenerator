{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions for 10/28 meeting:\n",
    "# Test set  -> Should the test be just one game? Answer: Leave it the way it is for now.\n",
    "# Train set -> Should we duplicate previous games to add weighting? Answer: Yes.\n",
    "\n",
    "## November 6th, 2020 Backend Meeting ##\n",
    "# 4 Factors to include for opponent: efg, tov_pct, orb_pct, ftr ... - Done\n",
    "# Add win (boolean) column for each game -> predict on that instead of points - Done\n",
    "# Later on: Using most recent games???\n",
    "\n",
    "## November 10th, 2020 Backend Meeting ##\n",
    "# Next Steps:\n",
    "# Get it on the dashboard\n",
    "# Other functionality?\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from matplotlib import pyplot\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in box score data provided by Ludis\n",
    "df = pd.read_csv(\"team_boxscores_v3.csv\")\n",
    "df = df.fillna(0)\n",
    "\n",
    "# pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_columns', 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hard-coded teamIDs from dataset for testing purposes ###\n",
    "\n",
    "# Kentucky\n",
    "team1 = '2267a1f4-68f6-418b-aaf6-2aa0c4b291f1'\n",
    "\n",
    "# LSU\n",
    "team2 = '70e2bedd-3a0a-479c-ac99-e3f58aa6824b'\n",
    "\n",
    "# Ohio State\n",
    "team3 = '857462b3-0ab6-4d26-9669-10ca354e382b'\n",
    "\n",
    "# Florida\n",
    "team4 = '912f8837-1d81-4ef9-a576-a21f271d4c64'\n",
    "\n",
    "# Michigan State\n",
    "team5 = 'a41d5a05-4c11-4171-a57e-e7a1ea325a6d'\n",
    "\n",
    "floatArr = [\"efg\",\"orb_pct\",\"ftr\"]\n",
    "negFloatArr = [\"tov_pct\"]\n",
    "intArr = [\"assists\", \"blocks\",\"defensive_rebounds\", \"fast_break_pts\", \"points_in_paint\",\"points_off_turnovers\",\"rebounds\",\"steals\"]\n",
    "negIntArr = [\"turnovers\",\"opponent_drb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns all game records for a given teamID\n",
    "def getAllTeamMatchRecords(teamID, df):\n",
    "    return df[df[\"team_id\"] == teamID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns win/loss ratio for a given team across entire dataset\n",
    "# Add functionality for filtering by season?\n",
    "def statWinLoss(teamID, df):\n",
    "    wins = 0\n",
    "    losses = 0\n",
    "    team_stats = df[df[\"team_id\"] == teamID]\n",
    "    for index, row in team_stats.iterrows():\n",
    "        if row[\"points\"] > row[\"points_against\"]:\n",
    "            wins = wins + 1\n",
    "        else:\n",
    "            losses = losses + 1\n",
    "    if losses == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return wins/losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return all gameIDs for a given team\n",
    "def getGameIDs(teamID, df):\n",
    "    return df[df[\"team_id\"] == teamID][\"game_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns common game IDs between two teams\n",
    "def getMatchupGameIDs(team1, team2, df):\n",
    "    return pd.merge(getGameIDs(team1, df), getGameIDs(team2, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns average of a given statistic for a given teamID\n",
    "def getAvgStatForTeam(teamID, statistic, df):\n",
    "        runningSum = 0\n",
    "        #runningSum = float(0)\n",
    "        runningCount = 0\n",
    "        team_stats = df[df[\"team_id\"] == teamID]\n",
    "        for index, row in team_stats.iterrows():\n",
    "            runningSum += row[statistic]\n",
    "            runningCount += 1\n",
    "         \n",
    "            return runningSum / runningCount\n",
    "            return runningSum / runningCount\n",
    "     \n",
    "        print(getAvgStatForTeam(team1, \"rebounds\", df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will get the record of a team by a specific year and can also calculate some avg\n",
    "def getTeamRecordByYear(teamID, year, df):\n",
    "    team_record = df[df[\"team_id\"] == teamID]\n",
    "    sum_two_pts_made = 0\n",
    "    count = 0\n",
    "    avg_two_pts_made = 0\n",
    "    sum_field_goals_made =0\n",
    "    count2 = 0\n",
    "    avg_field_goals_made = 0\n",
    "    for index, row in team_record.iterrows():\n",
    "        if (row[\"season\"] == year): \n",
    "           team_record1 = team_record[df[\"season\"] == row[\"season\"]]\n",
    "           for index, row in team_record1.iterrows():\n",
    "                sum_two_pts_made += row[\"two_points_made\"]\n",
    "                sum_field_goals_made += row[\"field_goals_made\"]\n",
    "                count +=1\n",
    "                count2 +=1\n",
    "           avg_two_pts_made = sum_two_pts_made / count\n",
    "           avg_field_goals_made = sum_field_goals_made / count2\n",
    "           return_value = \"%f %f\" %(avg_two_pts_made,avg_field_goals_made)\n",
    "           return team_record1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return dataframe with selected features\n",
    "def filterRowsFS(df):\n",
    "    return df[[\"assists\",\"blocks\",\"defensive_rebounds\",\"opponent_drb\",\"fast_break_pts\",\"points_in_paint\",\"points_off_turnovers\",\"rebounds\",\"steals\",\"turnovers\",\"efg\",\"tov_pct\",\"orb_pct\",\"ftr\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correct predictions -> wins/losses\n",
    "def calcPredError(df):\n",
    "    error = 0\n",
    "    correct = 0\n",
    "    i = 0\n",
    "    for index, row in df.iterrows():\n",
    "        i = i + 1\n",
    "        if df.loc[index, 'Actual'] != df.loc[index, 'Predicted (int)']:\n",
    "            error = error + 1\n",
    "        else:\n",
    "            correct = correct + 1\n",
    "    return ((correct / i) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate win percentage\n",
    "def winPct(teamPred):\n",
    "    # return round((teamPred['Predicted (float)'].sum() / len(teamPred['Predicted (float)']) * 100))\n",
    "    return float(teamPred['Predicted (float)'].sum() / len(teamPred['Predicted (float)']) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    # configure to select all features\n",
    "    fs = SelectKBest(score_func=f_regression, k='all')\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return list of top five features\n",
    "def overallFeatures(df):\n",
    "    datasetForFS = df\n",
    "    datasetForFS.fillna(0)\n",
    "\n",
    "    # X1 = datasetForFS[[\"assists\",\"personal_fouls\",\"ftr\",\"orb_pct\", \"tov_pct\", \"points_in_paint\", \"blocks\"]]\n",
    "    # X1 = datasetForFS[[\"assists\",\"blocks\",\"personal_fouls\"]]\n",
    "    X1 = datasetForFS[[\"assists\",\"blocks\",\"defensive_rebounds\",\"opponent_drb\",\"fast_break_pts\",\"points_in_paint\",\"points_off_turnovers\",\"rebounds\",\"steals\",\"turnovers\",\"efg\",\"tov_pct\",\"orb_pct\",\"ftr\"]]\n",
    "    y1 = datasetForFS['win']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=0)\n",
    "    X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "\n",
    "    colList = X1.columns.values.tolist()\n",
    "    statScoreDF = pd.DataFrame(data={'Stat': pd.Series(colList), 'Score': pd.Series(fs.scores_.tolist())})\n",
    "    statScoreDF = statScoreDF.sort_values(by=['Score'], ascending=False)\n",
    "\n",
    "    # plot the scores\n",
    "    # pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "    # pyplot.show()\n",
    "    \n",
    "    return statScoreDF.head(n=4)['Stat'].tolist()\n",
    "\n",
    "# team1df = getAllTeamMatchRecords(team1, df).merge(getMatchupGameIDs(team1, team2, df))\n",
    "# print(overallFeatures(team1df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Stat      Score\n",
      "10                   efg  62.521823\n",
      "11               tov_pct   8.348552\n",
      "0                assists   3.000000\n",
      "5        points_in_paint   3.000000\n",
      "9              turnovers   3.000000\n",
      "8                 steals   1.814815\n",
      "4         fast_break_pts   1.814815\n",
      "6   points_off_turnovers   0.925926\n",
      "1                 blocks   0.497942\n",
      "13                   ftr   0.123836\n",
      "3           opponent_drb   0.120000\n",
      "12               orb_pct   0.053885\n",
      "2     defensive_rebounds   0.006803\n",
      "7               rebounds   0.004115\n"
     ]
    }
   ],
   "source": [
    "def teamFeatures(team1, team2, df):\n",
    "    datasetForFS = getAllTeamMatchRecords(team1, df).merge(getMatchupGameIDs(team1, team2, df))\n",
    "    datasetForFS.fillna(0)\n",
    "\n",
    "    # X1 = datasetForFS[[\"assists\",\"personal_fouls\",\"ftr\",\"orb_pct\", \"tov_pct\", \"points_in_paint\", \"blocks\"]]\n",
    "    # X1 = datasetForFS[[\"assists\",\"blocks\",\"personal_fouls\"]]\n",
    "    X1 = datasetForFS[[\"assists\",\"blocks\",\"defensive_rebounds\",\"opponent_drb\",\"fast_break_pts\",\"points_in_paint\",\"points_off_turnovers\",\"rebounds\",\"steals\",\"turnovers\",\"efg\",\"tov_pct\",\"orb_pct\",\"ftr\"]]\n",
    "    y1 = datasetForFS['win']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=0)\n",
    "    X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "\n",
    "    colList = X1.columns.values.tolist()\n",
    "    statScoreDF = pd.DataFrame(data={'Stat': pd.Series(colList), 'Score': pd.Series(fs.scores_.tolist())})\n",
    "    statScoreDF = statScoreDF.sort_values(by=['Score'], ascending=False)\n",
    "\n",
    "    # Plot the scores - PyPlot\n",
    "    # pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "    # pyplot.show()\n",
    "    \n",
    "    return statScoreDF\n",
    "\n",
    "print(teamFeatures(team1, team2, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(dataset):\n",
    "    dataset = pd.read_csv(\"team_boxscores_v3.csv\")\n",
    "    dataset = dataset.fillna(0)\n",
    "    \n",
    "    # Shuffle\n",
    "    dataset = dataset.sample(frac = 1) \n",
    "    \n",
    "    X1 = dataset[[\"assists\",\"blocks\",\"defensive_rebounds\",\"opponent_drb\",\"fast_break_pts\",\"points_in_paint\",\"points_off_turnovers\",\"rebounds\",\"steals\",\"turnovers\",\"efg\",\"tov_pct\",\"orb_pct\",\"ftr\"]]\n",
    "    y1 = dataset['win']\n",
    "    \n",
    "    # No shuffle\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=0)\n",
    "    \n",
    "    # W/ shuffle\n",
    "    X_train = X1[int(len(X1)/5):]\n",
    "    X_test = X1[:int(len(X1)/5)]\n",
    "    \n",
    "    y_train = y1[int(len(y1)/5):]\n",
    "    y_test = y1[:int(len(y1)/5)]\n",
    "    \n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X_train, y_train)\n",
    "    \n",
    "    coeff_df = pd.DataFrame(regressor.coef_, X1.columns, columns=['Coefficient'])\n",
    "    \n",
    "    y_pred = regressor.predict(X_test)\n",
    "    y_pred_round = np.around(regressor.predict(X_test))\n",
    "    \n",
    "    # print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "    # print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "    # print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    \n",
    "    return regressor, pd.DataFrame({'Actual': y_test, 'Predicted (int)': y_pred_round, 'Predicted (float)': y_pred})\n",
    "\n",
    "reg, pred = learn(pd.read_csv(\"team_boxscores_v3.csv\"))\n",
    "# print(calcPredError(pred), winPct(pred))\n",
    "\n",
    "# df1 = filterRowsFS(getAllTeamMatchRecords(team1, df))\n",
    "# df2 = getAllTeamMatchRecords(team1, df)[\"win\"]\n",
    "# dfPred = reg.predict(df1)\n",
    "# dfPredRound = np.around(dfPred)\n",
    "\n",
    "# temp = pd.DataFrame({'Actual': df2, 'Predicted (int)': dfPredRound, 'Predicted (float)': dfPred})\n",
    "\n",
    "# print(calcPredError(temp), winPct(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.2726980125736819\n",
      "Mean Squared Error: 0.12316226515767659\n",
      "Root Mean Squared Error: 0.3509448178242223\n"
     ]
    }
   ],
   "source": [
    "def learnMatchup(team1, team2):\n",
    "    dataset = pd.read_csv(\"team_boxscores_v3.csv\")\n",
    "    dataset = dataset.fillna(0)\n",
    "    dfTeam1 = getAllTeamMatchRecords(team1, dataset)\n",
    "    matchups = getMatchupGameIDs(team1, team2, df)[\"game_id\"].tolist()\n",
    "    dfTeam1 = dfTeam1.reset_index()\n",
    "    \n",
    "    # Elijah - Save rows for later and append to train set\n",
    "    for index, row in dfTeam1.iterrows():\n",
    "        for i in range(0, len(matchups)):\n",
    "            if str(dfTeam1.loc[index, \"game_id\"]) == matchups[i]:\n",
    "                dfTeam1 = dfTeam1.append(dfTeam1.loc[index], ignore_index=True)\n",
    "    \n",
    "    dfTeam1 = dfTeam1.sample(frac = 1) \n",
    "                \n",
    "    X1 = dfTeam1[[\"assists\",\"blocks\",\"defensive_rebounds\",\"opponent_drb\",\"fast_break_pts\",\"points_in_paint\",\"points_off_turnovers\",\"rebounds\",\"steals\",\"turnovers\",\"efg\",\"tov_pct\",\"orb_pct\",\"ftr\"]]\n",
    "    y1 = dfTeam1['win']\n",
    "    \n",
    "    # rng = np.random.randint(0, 42)\n",
    "    rng = 0\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=rng)\n",
    "    \n",
    "    # W/ shuffle\n",
    "    X_train = X1[int(len(X1)/5):]\n",
    "    X_test = X1[:int(len(X1)/5)]\n",
    "    \n",
    "    y_train = y1[int(len(y1)/5):]\n",
    "    y_test = y1[:int(len(y1)/5)]\n",
    "    \n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X_train, y_train)\n",
    "    \n",
    "    coeff_df = pd.DataFrame(regressor.coef_, X1.columns, columns=['Coefficient'])\n",
    "    \n",
    "    y_pred = regressor.predict(X_test)\n",
    "    y_pred_round = np.around(regressor.predict(X_test))\n",
    "    \n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    \n",
    "    return regressor, pd.DataFrame({'Actual': y_test, 'Predicted (int)': y_pred_round, 'Predicted (float)': y_pred})\n",
    "\n",
    "reg1, pred1 = learnMatchup(team1, team2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgDataRow(df):\n",
    "    df1 = dict()\n",
    "    for (columnName, columnData) in df.iteritems():\n",
    "        df1[columnName] = [df[columnName].mean()]\n",
    "    \n",
    "    return pd.DataFrame(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return win percentage as stat changes\n",
    "# df - dataframe, e.g. getAllTeamMatchRecords(team1, df)\n",
    "# reg - regressor from above\n",
    "# var - the feature to change\n",
    "# val - the value to add to the feature\n",
    "def predOnStat(df, reg, var, val):\n",
    "    df1 = df[[\"assists\",\"blocks\",\"defensive_rebounds\",\"opponent_drb\",\"fast_break_pts\",\"points_in_paint\",\"points_off_turnovers\",\"rebounds\",\"steals\",\"turnovers\",\"efg\",\"tov_pct\",\"orb_pct\",\"ftr\"]]\n",
    "    for index, row in df1.iterrows():\n",
    "        df1.at[index, var] = df1.at[index, var] + val\n",
    "    \n",
    "    temp_pred = reg.predict(df1)\n",
    "    temp_pred_round = np.around(reg.predict(df1))\n",
    "    \n",
    "    test = pd.DataFrame({'Actual': df['win'], 'Predicted (int)': temp_pred_round, 'Predicted (float)': temp_pred})\n",
    "    return float(winPct(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfMain -> main dataframe\n",
    "# dfWin  -> win column\n",
    "# reg    -> regressor\n",
    "# Return new win pct\n",
    "def updateWinPct(dfMain, dfWin, reg):\n",
    "    dfPred = reg.predict(dfMain)\n",
    "    return pd.DataFrame({'Actual': dfWin.mean(), 'Predicted (int)': np.around(dfPred), 'Predicted (float)': dfPred})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['efg', 'opponent_drb', 'assists', 'orb_pct']\n"
     ]
    }
   ],
   "source": [
    "## Main ##\n",
    "\n",
    "# team1: Kentucky - team2: LSU\n",
    "team1 = '2267a1f4-68f6-418b-aaf6-2aa0c4b291f1'\n",
    "team2 = '70e2bedd-3a0a-479c-ac99-e3f58aa6824b'\n",
    "\n",
    "stats = overallFeatures(getAllTeamMatchRecords(team1, df))\n",
    "print(stats)\n",
    "\n",
    "# Default values\n",
    "dfMain = avgDataRow(filterRowsFS(getAllTeamMatchRecords(team1, df)))\n",
    "\n",
    "# Win column\n",
    "dfWin = getAllTeamMatchRecords(team1, df)[\"win\"]\n",
    "\n",
    "# dfPred = reg.predict(dfMain)\n",
    "dfFinal = pd.DataFrame({'Actual': dfWin.mean(), 'Predicted (int)': np.around(reg.predict(dfMain)), 'Predicted (float)': reg.predict(dfMain)})\n",
    "origWinPct = dfFinal.at[0, 'Predicted (float)']\n",
    "# print(\"Original Win Percentage:\", origWinPct)\n",
    "\n",
    "# Update test row here\n",
    "# Some thing like dfMain = [stuff from front end]\n",
    "\n",
    "dfMain.at[0, \"assists\"] = dfMain.at[0, \"assists\"] + 1\n",
    "dfMain.at[0, \"blocks\"] = dfMain.at[0, \"blocks\"] + 1\n",
    "\n",
    "# print(dfMain)\n",
    "\n",
    "dfFinal = updateWinPct(dfMain, dfWin, reg)\n",
    "newWinPct = dfFinal.at[0, 'Predicted (float)']\n",
    "# print(newWinPct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
